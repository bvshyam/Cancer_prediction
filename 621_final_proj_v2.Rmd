---
title: "DATA 621 Final Project"
#author: "Marco Siqueira Campos"
date: "`r format(Sys.Date(), format='%B %d, %Y')`"
output: 
        pdf_document:
                latex_engine: xelatex
mainfont: Calibri Light 
fontsize: 12pt

---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

####DATA 621  
####MSDS CUNY  

#### Final Project 
Wisconsin Diagnostic Breast Cancer (WDBC)

### Team: Christopher Estevez and Marco Siqueira Campos.   
 
 
### Project Description

*MOTIVATION*  
*WHAT IS THE QUESTION?*

Features are computed from a digitized image of a fine needle aspirate (FNA) of a breast mass. They describe characteristics of the cell nuclei present in the image. 

The mean, standard error, and "worst" or largest (mean of the three
largest values) of these features were computed for each image,
resulting in 30 features.  For instance, field 3 is Mean Radius, field
13 is Radius SE, field 23 is Worst Radius.





### 1. DATA EXPLORATION 

Variable description

1) ID number
2) diagnosis (M = malignant, B = benign), this we changed for (1 = malignant, 0 = benign).

Ten real-valued features are computed for each cell nucleus: 

a) radius (mean of distances from center to points on the perimeter)
b) texture (standard deviation of gray-scale values)
c) perimeter
d) area
e) smoothness (local variation in radius lengths)
f) compactness (perimeter^2 / area - 1.0)
g) concavity (severity of concave portions of the contour)
h) concave points (number of concave portions of the contour)
i) symmetry
j) fractal dimension ("coastline approximation" - 1)

For each variable we have 3 different statistics: Mean, standard error and worst case.
We have a total of 30 predictors.

The change `diagnosis` predictor from malignant for 1, benign for 0, help us to see relationship beetwen the response and the predictors, and was done in this phase.


```{r, echo=FALSE, warning=FALSE, message=FALSE}
#load libraries
library(xlsx)
library(psych)
library(GGally)
library(ggplot2)
library(caret)
library(dplyr)
library(pROC)
library(car)
library(leaps)
library(sjstats)
```

```{r, echo=FALSE, cache=TRUE}
#load dataset 
WDBCdata<-read.xlsx("data_with groups.xlsx", sheetName = "ics data")
```

```{r, echo=FALSE, cache=TRUE}
# First step the id will be removed to avoid any future trouble
# change M = malignant for 1 and B for B = benign for zero
WDBCdata$mycol<-NULL
WDBCdata$id<-NULL
WDBCdata$diagnosis<-ifelse(WDBCdata$diagnosis == "B", 0, 1)
```

Summary statistics

```{r, echo=FALSE}
#summary stats
WDBC_tbl<-describe(WDBCdata,IQR=T)[,c(1:5,8:10,11,12)]
knitr::kable(round(WDBC_tbl,2), caption = "Selected Stats")
rm(WDBC_tbl)
```

Histograms

```{r, echo=FALSE, fig.width=7, fig.height=8, message=F, warning=F}
library(Hmisc)
hist.data.frame(WDBCdata, n.unique=1, mtitl = "Breast Cancer Histogram")
```
\begin{center}
fig. 1
\end{center}


BOX-PLOT

```{r ,echo=FALSE, fig.align="center", fig.height=4, fig.width=6}
# boxplot
par(cex.axis=0.8) # is for x-axis
boxplot(WDBCdata[,c(2:15)], las=2, col="red", main="Breast Cancer Box-Plot" )
boxplot(WDBCdata[,c(16:31)], las=2, col="red", main="Breast Cancer Box-Plot" )

```

\begin{center}
fig. 2
\end{center}

BOX-PLOT

```{r ,echo=FALSE, fig.align="center", fig.height=4, fig.width=6}
# boxplot
par(cex.axis=0.8) # is for x-axis
boxplot(WDBCdata[,c(2:15)], las=2, col="green", main="Breast Cancer Box-Plot, y axis changed", ylim = c(0,150))
boxplot(WDBCdata[,c(16:31)], las=2, col="green", main="Breast Cancer Box-Plot, y axis changed", ylim = c(0,150))

```
  
\begin{center}
fig. 3
\end{center}


Correlation matrix

```{r ,echo=FALSE}
ggcorr(WDBCdata, nbreaks=8, palette='PRGn', label=TRUE, label_size=2, size = 1.8, label_color='black') + ggtitle("Breast Cancer Correlation Matrix") + theme(plot.title = element_text(hjust = 0.5, color = "grey15"))
```

\begin{center}
fig. 4
\end{center}

Correlation list (only high correlation values, r>0.9)
```{r ,echo=FALSE}
z = cor(WDBCdata)

z = round(z,4)
z[abs(z)<0.9]=NA # remove low relationship
z[lower.tri(z,diag=TRUE)]=NA  #Prepare to drop duplicates and meaningless information
z=as.data.frame(as.table(z))  #Turn into a 3-column table
z=na.omit(z)  #Get rid of the junk we flagged above
z=z[order(-abs(z$Freq)),]    #Sort by highest correlation (whether +ve or -ve)
z
rm(z)
```

Summary of data explorations findings:

- Most histograms present very asymmetric behavior with similar to exponential distribution.
- Some predictor look like exponential distribuition as `radius_se`, `perimeter_se`, `area_se`, `concavity_se` and `fractal_dimension_se`.
- There is no true outliers, the outliers at box-plot is due the kind of distribution.
- There is no missing.
- we identified 21 pairs of highly correlated predictors, r> 0.9, this was due to the choice of predictors that are associated, measures things related: radius, perimeter and area.
- There are 14 predictors related with the response, `Diagnosis`, with r>=0.6, this is a good news.  

###2. DATA PREPARATION

The to solve the issues the follow activities will be done:

- Solve high correlations values, the follow predictors were removed: `area_mean`, `radius_mean`, `area_worst`, `compactness_mean`, `perimeter_worst`, `compactness_se`. `concavity_worst`and `fractal_dimension_worst`.
- Verify the data behavior of power transformation for the follow predictors: `radius_se`, `perimeter_se`, `area_se` and `fractal_dimension_se`.


```{r ,echo=FALSE,fig.align="center", fig.height=3, fig.width=5}

bc1<-BoxCoxTrans(WDBCdata$radius_se)
bc2<-BoxCoxTrans(WDBCdata$perimeter_se)
bc3<-BoxCoxTrans(WDBCdata$area_se )
bc5<-BoxCoxTrans(WDBCdata$fractal_dimension_se)

par(mfrow=c(1,2))
hist(WDBCdata$radius_se, main="Histogram radius_se")
hist(WDBCdata$radius_se^bc1$lambda, main="Histogram radius_se transf.")
par(mfrow=c(1,2))
hist(WDBCdata$perimeter_se, main="Histogram perimeter_se")
hist(WDBCdata$perimeter_se^bc2$lambda, main="Histogram perimeter_se transf.")
par(mfrow=c(1,2))
hist(WDBCdata$area_se, main="Histogram area_se")
hist(WDBCdata$area_se^bc3$lambda, main="Histogram area_se transf.")
par(mfrow=c(1,2))
hist(WDBCdata$fractal_dimension_se, main="Histogram dimension_se")
hist(WDBCdata$fractal_dimension_se^bc5$lambda, main="Histogram dimension_se transf.")
par(mfrow=c(1,1))

```
\begin{center}
fig. 3
\end{center}

As we saw in the chart, figure 3, the power transformation, improve the distribution and will be applied.

```{r, echo=FALSE}
# code to compute VIF to indentify predictors to drop

#vif_logit<-glm(WDBCdata$diagnosis ~. -diagnosis,family=binomial,data=WDBCdata)
#vif(vif_logit)
```

We split the data in two data set, Train data set with 70% and Test data set with 30% of all data 

```{r, echo=FALSE, cache=TRUE}

WDBCdatafull<-WDBCdata #copy data set

WDBCdata<-subset(WDBCdata, select=-c(area_mean,radius_mean,area_worst,compactness_mean,perimeter_worst,compactness_se,concavity_worst,fractal_dimension_worst)) # remove predictors


# WDBCdatafull all predictors
# WDBCdata remove highly correlated predictors


set.seed(123)
indx<-createDataPartition(WDBCdata$diagnosis, p=0.7, list=FALSE)

train_x<-WDBCdata[indx,-1]
train_y<-WDBCdata$diagnosis[indx]

test_x<-WDBCdata[-indx,-1]
test_y<-WDBCdata$diagnosis[-indx]


# the subset bellow is with full predictors, cannot be used with logistic model, only can be used with model that accept highly correlated predictors.

trainfull_x<-WDBCdatafull[indx,-1]
trainfull_y<-WDBCdatafull$diagnosis[indx]

testfull_x<-WDBCdatafull[-indx,-1]
testfull_y<-WDBCdatafull$diagnosis[-indx]

```        


```{r, echo=FALSE, cache=TRUE}
# applying the power transformation for the test and train data set

train_x$radius_se<-train_x$radius_se^bc1$lambda
train_x$perimeter_se<-train_x$perimeter_se^bc2$lambda    
train_x$area_se<-train_x$area_se^bc3$lambda
train_x$fractal_dimension_se<-train_x$fractal_dimension_se^bc5$lambda

test_x$radius_se<-test_x$radius_se^bc1$lambda
test_x$perimeter_se<-test_x$perimeter_se^bc2$lambda    
test_x$area_se<-test_x$area_se^bc3$lambda
test_x$fractal_dimension_se<-test_x$fractal_dimension_se^bc5$lambda

``` 

###3. BUILD MODEL 

A two models was chosen one linear, Logistic regression and a rule based/tree model, Cubist regression.

Cubist is a prediction-oriented regression model that combines the ideas in Quinlan (1992) and Quinlan (1993).  
Although it initially creates a tree structure, it collapses each path through the tree into a rule. A regression model is fit for each rule based on the data subset defined by the rules. The set of rules are pruned or possibly combined. and the candidate variables for the linear regression models are the predictors that were used in the parts of the rule that were pruned away. This part of the algorithm is consistent with the "M5" or Model Tree approach.  
Cubist generalizes this model to add boosting (when committees > 1) and instance based corrections (see predict.cubist()). The number of instances is set at prediction time by the user and is not needed for model building.

**Logistic Model:**

The model was done by manual backward.
The follow predictors was chosen:
- `perimeter_mean` 
- `concavity_mean`
- `concavity_se`
- `concave.points_se`
- `fractal_dimension_se`
- `radius_worst` 
- `texture_worst`
- `smoothness_worst`

```{r, echo=FALSE, cache=TRUE}
model_logit<-glm( train_y~. -symmetry_se -concave.points_worst -texture_se -perimeter_se 
                  -fractal_dimension_mean -symmetry_mean -texture_mean -concave.points_mean
                  -compactness_worst -symmetry_worst -smoothness_se -smoothness_mean -area_se -radius_se,family=binomial,data=train_x)
summary(model_logit)
``` 


**Cubist Model:**

```{r, echo=FALSE, cache=TRUE}
set.seed(123)
ctrl=(trainControl(method="repeatedcv", repeats=5))

c<-c(1,3,5,10,20,30,50,80,100)
n<-c(0,1,3,5,7)

cube_fit<-train(train_x,train_y, method="cubist",
                preProcess = c("center", "scale"),
                tuneGrid = expand.grid(committees=c,neighbors=n),
                trControl = ctrl)

``` 

Predictor importance from cubist model

```{r, echo=FALSE, cache=TRUE}

dotPlot(varImp(cube_fit), main="Cubist Predictor importance")

``` 

\begin{center}
fig. 4
\end{center}


###3.1 MODEL ANALYSIS AND DIAGNOSTIC 

Several models was tested, were the best performance model with linear and rule basead/tree mode was chosen.


The predited data, response, was converted to dicrete 0/1.  



**PERFORMANCE ANALYSIS WITH TRAIN DATA**

**Logistic Model**
```{r, echo=FALSE, cache=TRUE}
logit_pred_train <- ifelse(predict(model_logit) > 0.5,1,0)
conf_logit<-confusionMatrix(logit_pred_train,train_y,positive="1")
conf_logit
``` 
  
**Cubist Model**
```{r, echo=FALSE, cache=TRUE, warning=FALSE}
cube_pred_train <- ifelse(predict(cube_fit) > 0.5,1,0)
conf_cube<-confusionMatrix(cube_pred_train,train_y,positive="1")
conf_cube
``` 

  
**PERFORMANCE ANALYSIS WITH TEST DATA**


**Logistic Model**
```{r, echo=FALSE, cache=TRUE}
logit_pred_test <- ifelse(predict(model_logit, newdata=test_x) > 0.5,1,0)
conf_test_logit <- confusionMatrix(logit_pred_test,test_y,positive="1")
conf_test_logit
```

**Cubist Model**
```{r, echo=FALSE, cache=TRUE}
cube_pred_test <-  ifelse(predict(cube_fit, newdata=test_x) > 0.5,1,0)
conf_test_cube<-confusionMatrix(cube_pred_test,test_y,positive="1")
conf_test_cube
```


###4 CONCLUSION




REFERENCES:  
[1] Dua, D. and Karra Taniskidou, E. (2017). UCI Machine Learning Repository [http://archive.ics.uci.edu/ml]. Irvine, CA: University of California, School of Information and Computer Science.    
[2] https://stackoverflow.com/questions/7074246/show-correlations-as-an-ordered-list-not-as-a-large-matrix
[3] https://cran.r-project.org/web/packages/Cubist/Cubist.pdf